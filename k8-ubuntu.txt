Steps to setup K8-cluster in ubuntu Flavour (combination of worker nodes and master node is called as Kubernetes cluster)
========================================================================================================================
Initially check this and add the all 3 nodes
============================================

kubectl commands should only run in master node, not in worker nodes
====================================================================



1. sudo hostnamectl set-hostname k8master after this run this command sudo exec bash (run only in master node)
   Sudo hostnamectl set-hostname k8node1. after this run this command sudo exec bash. (run only in worker node1)
   Sudo hostnamectl set-hostname k8node2. after this run this command sudo exec bash. (run only in worker node2
   


2. go to vim /etc/hosts and add this in each node all 3 sub steps

example:  0.0.0.0       k8master.gonext.com       k8master
example:  1.1.1.1       k8node1.gonext.com       k8node1
example:  2.2.2.2.      k8node2.gonext.com       k8node2

This step because all the 3 nodes should communicate each other.
 
3. Pinging should do work and Enable ICMP V4 

4. Firewalld package should be installed in AWS Ubuntu OS, and Disabled.
   
   Sudo apt install firewalld
   Sudo systemctl status firewall
   Sudo systemctl stop firewall

5. SWAP memory will not support for K8, because cache memory will not required.

   sudo Free -m
   sudo Swappoff -a

6. SeLinux is disabled 
   sudo Sestatus
   sudo setenforce 0
   sudo Sestatus


7. sudo apt-get update && sudo apt-get install -y apt-transport-https curl

8. curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

9. sudo apt-add-repository "deb http://apt.kubernetes.io/ kubernetes-xenial main"

10. Sudo apt update

11. Install docker and enable the services in all 3 nodes
    Sudo apt install docker.io
    Sudo systemctl start docker
    Sudo systemctl enable docker

12. Install the Kubeadm, kubelet , kubectl  in all 3 nodes
    
   sudo apt-get install -y kubelet kubeadm kubectl 
   
13. Check the version kubeadm

14. Start the kubelet and enable the services of kubelet
    Sudo systemctl start kubelet
    Sudo systemctl enable kubelet


Only in Master node-Run the following commands and network add ons plugins in master node only.
================================================================================================

15. Add the environemnt details for Cgroup of dockers and kubelet for systems in a file kubernetes environmental file only in master node
    
    Environment="cgroup-driver=systemd/cgroup-driver=cgroupfs"



16. sudo kubeadm init --apiserver-advertise-address **PROVIDE IP ADDRESS of master node** --pod-network-cidr=192.168.0.0/16
       Or
      sudo kubeadm init --pod-network-cidr=10.244.0.0/16

17. kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml


18.  mkdir -p $HOME/.kube
       sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
       sudo chown $(id -u):$(id -g) $HOME/.kube/config

19. Run kubectl get nodes. To verify all the 3 nodes are active or not.

20. Kubectl get pods --all-namespaces

21. Save the Generated token, with this token we have to join the worker nodes to master node
   example:  kubeadm join 172.31.45.220:6443 --token 4dpaz7.1d4qr7d06m46ta2n     --discovery-token-ca-cert-hash       sha256:94d0de44045b5a94507a3586ff68532fc7da62f45841c72d22622dbc9a5d23be 



In worker nodes
===============

1. 1 to 14 steps should run

2. kubeadm join generated token in master node.



Port numbers for master node and worker node details:
=====================================================
In master node these port numbers should be allowed
====================================================

Protocol	Direction	Port Range	Purpose	              Used By
==============================================================================
TCP	        Inbound	          6443*	     Kubernetes API server	All
TCP	        Inbound           2379-2380  etcd server client API	kube-apiserver, etcd
TCP	        Inbound	          10250	     Kubelet API	        Self, Control plane
TCP	        Inbound	          10251	    kube-scheduler	        Self
TCP	        Inbound	          10252	    kube-controller-manager	Self


In worker node these port numbers should be allowed
=====================================================
Protocol	Direction	Port Range	Purpose	              Used By
==============================================================================
TCP	        Inbound	        10250	        Kubelet API	        Self, Control plane
TCP	        Inbound	        30000-32767	NodePort Servicesâ€ 	All




Required Port numbers in master node for Kubernetes cluster only in Master node
===============================================================================
firewall-cmd --permanent --add-port=6443/tcp
firewall-cmd --permanent --add-port=2379-2380/tcp
firewall-cmd --permanent --add-port=10250/tcp
firewall-cmd --permanent --add-port=10251/tcp
firewall-cmd --permanent --add-port=10252/tcp
firewall-cmd --permanent --add-port=10255/tcp
firewall-cmd --reload
And additional port numbers if required

8080
8081
8082
8443
9090



Required Port numbers for only  in worker nodes
========================================
Enable the port numbers range from 
30000-32767

firewall-cmd --permanent --add-port=10255/tcp
firewall-cmd --permanent --add-port=130000/tcp

To
firewall-cmd --permanent --add-port=32767/tcp
firewall-cmd --reload



https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#control-plane-nodes
https://kubernetes.io/docs/concepts/services-networking/service/
